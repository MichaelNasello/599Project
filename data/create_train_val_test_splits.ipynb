{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataloader import load_patient_task_data_from_txt, clean_and_verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine valid columns\n",
    "\n",
    "We want to eliminate features that are not present for all samples, as we won't be able to always feed them to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns\n",
    "total_cols = ['RTA', 'LTA', 'IO', 'ECG', 'RGS', 'acc_x_left_shank', 'acc_y_left_shank', 'acc_z_left_shank', 'gyro_x_left_shank', 'gyro_y_left_shank', 'gyro_z_left_shank', 'NC_invalid_0', 'acc_x_right_shank', 'acc_y_right_shank', 'acc_z_right_shank', 'gyro_x_right_shank', 'gyro_y_right_shank', 'gyro_z_right_shank', 'NC_invalid_1', 'acc_x_waist', 'acc_y_waist', 'acc_z_waist', 'gyro_x_waist', 'gyro_y_waist', 'gyro_z_waist', 'NC_invalid_2', 'acc_x_arm', 'acc_y_arm', 'acc_z_arm', 'gyro_x_arm', 'gyro_y_arm', 'gyro_z_arm', 'SC']\n",
    "\n",
    "# Merging left_shank and right_shank to shank\n",
    "for i, col in enumerate(total_cols):\n",
    "    if 'left' in col:\n",
    "        total_cols[i] = ''.join(col.split('_left'))\n",
    "    if 'right' in col:\n",
    "        total_cols[i] = ''.join(col.split('_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for patient_id=001, task=5\n",
      "No data found for patient_id=001, task=6\n",
      "No data found for patient_id=002, task=5\n",
      "No data found for patient_id=002, task=6\n",
      "No data found for patient_id=003, task=5\n",
      "No data found for patient_id=003, task=6\n",
      "No data found for patient_id=004, task=6\n",
      "No data found for patient_id=005, task=5\n",
      "No data found for patient_id=005, task=6\n",
      "No data found for patient_id=006, task=5\n",
      "No data found for patient_id=006, task=6\n",
      "No data found for patient_id=007, task=5\n",
      "No data found for patient_id=007, task=6\n",
      "No data found for patient_id=008-1, task=6\n",
      "No data found for patient_id=008-2, task=5\n",
      "No data found for patient_id=008-2, task=6\n",
      "No data found for patient_id=010, task=5\n",
      "No data found for patient_id=010, task=6\n",
      "No data found for patient_id=011, task=5\n",
      "No data found for patient_id=011, task=6\n",
      "No data found for patient_id=012, task=5\n",
      "No data found for patient_id=012, task=6\n",
      "\n",
      "Cannot use the following features: ['SC', 'gyro_y_waist', 'acc_x_arm', 'NC_invalid_2', 'gyro_x_waist', 'acc_z_arm', 'acc_y_arm', 'NC_invalid_0', 'acc_z_waist', 'gyro_y_arm', 'gyro_z_waist', 'NC_invalid_1', 'acc_x_waist', 'acc_y_waist', 'gyro_z_arm', 'gyro_x_arm']\n"
     ]
    }
   ],
   "source": [
    "# Get list of unusable features\n",
    "unusable = []\n",
    "for patient_id in ['001', '002', '003', '004', '005', '006', '007', '008-1', '008-2', '009', '010', '011', '012']:\n",
    "    for task_num in [i for i in range(1, 7)]:\n",
    "        patient_x_task_y_data = load_patient_task_data_from_txt(patient_id, task_num)\n",
    "        patient_x_task_y_data = clean_and_verify(patient_x_task_y_data)\n",
    "        \n",
    "        if not patient_x_task_y_data.empty:\n",
    "            cols = patient_x_task_y_data.columns.values.tolist()\n",
    "            unusable += [col for col in total_cols if col not in cols]\n",
    "        else:\n",
    "            print(f'No data found for patient_id={patient_id}, task={task_num}')\n",
    "                  \n",
    "unusable = list(set(unusable))\n",
    "print(f'\\nCannot use the following features: {unusable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can use the following features: ['RTA', 'LTA', 'IO', 'ECG', 'RGS', 'acc_x_shank', 'acc_y_shank', 'acc_z_shank', 'gyro_x_shank', 'gyro_y_shank', 'gyro_z_shank', 'acc_x_shank', 'acc_y_shank', 'acc_z_shank', 'gyro_x_shank', 'gyro_y_shank', 'gyro_z_shank', 'label']\n"
     ]
    }
   ],
   "source": [
    "# Get list of usable features\n",
    "usable = [col for col in total_cols if col not in unusable] + ['label']\n",
    "print(f'We can use the following features: {usable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(usable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amalgamate data from different patients, tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting for patient 001, task 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 635/1805 [00:02<00:03, 292.95it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(patient_data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m                 patient_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpatient_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatient_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, patient_data)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for patient_id in ['001', '002', '003', '004', '005', '006', '007', '008-1', '008-2', '009', '010', '011', '012']:\n",
    "    patient_data = None  # filled with [n_samples, window_size, n_features]\n",
    "    for task_num in [i for i in range(1, 7)]:\n",
    "        print(f'\\nCollecting for patient {patient_id}, task {task_num}...')\n",
    "        \n",
    "        patient_x_task_y_data = load_patient_task_data_from_txt(patient_id, task_num)\n",
    "        patient_x_task_y_data = clean_and_verify(patient_x_task_y_data)\n",
    "        \n",
    "        if 'label' not in patient_x_task_y_data.columns:\n",
    "            continue\n",
    "        \n",
    "        # Remove unusable columns\n",
    "        patient_x_task_y_data = patient_x_task_y_data[usable]\n",
    "        \n",
    "        # Break into windows\n",
    "        for i in tqdm(range(len(patient_x_task_y_data) // window_size)):\n",
    "            window = patient_x_task_y_data.loc[i * window_size: i * window_size + window_size - 1].values\n",
    "            window = np.expand_dims(window, axis=0)\n",
    "            \n",
    "            if patient_data is None:\n",
    "                patient_data = window\n",
    "            else:\n",
    "                patient_data = np.concatenate([patient_data, window], axis=0)\n",
    "                \n",
    "    np.save(f'{patient_id}.npy', patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = None\n",
    "for patient_id in ['001', '002', '003', '004', '005', '006', '007', '008-1', '008-2', '009', '010', '011', '012']:\n",
    "    patient_data = np.load(f'{patient_id}.npy', allow_pickle=True)\n",
    "    \n",
    "    if all_data is None:\n",
    "        all_data = patient_data\n",
    "    else:\n",
    "        if len(patient_data.shape) == 3:\n",
    "            all_data = np.concatenate([all_data, patient_data], axis=0)\n",
    "            \n",
    "    os.remove(f'{patient_id}.npy')\n",
    "        \n",
    "np.save('train.npy', all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_data[:, :, 0:-1]\n",
    "y = all_data[:, :, -1]\n",
    "\n",
    "x_train, x_val_test, y_train, y_val_test = train_test_split(x, y, train_size=0.7, random_state=0)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, train_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_train.npy', x_train)\n",
    "np.save('x_val.npy', x_val)\n",
    "np.save('x_test.npy', x_test)\n",
    "\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_val.npy', y_val)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
