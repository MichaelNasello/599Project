{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "from dataloader2 import load_patient_task_data_from_txt, clean_and_verify\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine valid columns\n",
    "\n",
    "We want to eliminate features that are not present for all samples, as we won't be able to always feed them to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns\n",
    "all_patient_ids = ['001', '002', '003', '004', '005', '006', '007', '008-1', '008-2', '009', '010', '011', '012']\n",
    "total_cols = ['RTA', 'LTA', 'IO', 'ECG', 'RGS', 'acc_x_left_shank', 'acc_y_left_shank', 'acc_z_left_shank',\n",
    "              'gyro_x_left_shank', 'gyro_y_left_shank', 'gyro_z_left_shank', 'NC_invalid_0', 'acc_x_right_shank',\n",
    "              'acc_y_right_shank', 'acc_z_right_shank', 'gyro_x_right_shank', 'gyro_y_right_shank', \n",
    "              'gyro_z_right_shank', 'NC_invalid_1', 'acc_x_waist', 'acc_y_waist', 'acc_z_waist', 'gyro_x_waist', \n",
    "              'gyro_y_waist', 'gyro_z_waist', 'NC_invalid_2', 'acc_x_arm', 'acc_y_arm', 'acc_z_arm', 'gyro_x_arm',\n",
    "              'gyro_y_arm', 'gyro_z_arm', 'SC']\n",
    "total_cols = [i for i in total_cols if 'NC_invalid' not in i]\n",
    "# Merging left_shank and right_shank to shank\n",
    "# for i, col in enumerate(total_cols):\n",
    "#     if 'left' in col:\n",
    "#         total_cols[i] = ''.join(col.split('_left'))\n",
    "#     if 'right' in col:\n",
    "#         total_cols[i] = ''.join(col.split('_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of unusable features\n",
    "unusable = []\n",
    "means_col_val = {col:[] for col in total_cols}\n",
    "std_col_val = {col:[] for col in total_cols}\n",
    "for patient_id in all_patient_ids:\n",
    "    for task_num in [i for i in range(1, 7)]:\n",
    "        patient_x_task_y_data = load_patient_task_data_from_txt(patient_id, task_num)\n",
    "        patient_x_task_y_data = clean_and_verify(patient_x_task_y_data)\n",
    "        for col in total_cols:\n",
    "            if col in patient_x_task_y_data.columns and not patient_x_task_y_data[col].isnull().values.any():\n",
    "                means_col_val[col].append(patient_x_task_y_data[col].mean())\n",
    "                std_col_val[col].append(patient_x_task_y_data[col].std())\n",
    "#         if not patient_x_task_y_data.empty:\n",
    "#             cols = patient_x_task_y_data.columns.values.tolist()\n",
    "#             unusable += [col for col in total_cols if col not in cols]\n",
    "#         else:\n",
    "#             print(f'No data found for patient_id={patient_id}, task={task_num}')\n",
    "for k, lst in means_col_val.items():\n",
    "    means_col_val[k] = mean(lst)\n",
    "unusable = list(set(unusable))\n",
    "print(f'\\nCannot use the following features: {unusable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col std values saved for data augmentation\n",
    "with open(\"std_col_val.pickle\", 'wb') as file:\n",
    "    pickle.dump(std_col_val, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of usable features\n",
    "usable = [col for col in total_cols if col not in unusable] + ['label']\n",
    "print(f'We can use the following features: {usable}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amalgamate data from different patients, tasks with window overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1000\n",
    "jump = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_id in ['001', '002', '003', '004', '005', '006', '007', '008-1', '008-2', '009', '010', '011', '012']:\n",
    "    patient_data = None  # filled with [n_samples, window_size, n_features]\n",
    "    for task_num in [i for i in range(1, 7)]:\n",
    "        print(f'\\nCollecting for patient {patient_id}, task {task_num}...')\n",
    "        \n",
    "        patient_x_task_y_data = load_patient_task_data_from_txt(patient_id, task_num)\n",
    "        patient_x_task_y_data = clean_and_verify(patient_x_task_y_data)\n",
    "        # constant 0 replacement\n",
    "        patient_x_task_y_data.fillna(0.0, inplace=True)\n",
    "        # mean value replacement\n",
    "#         for col in total_cols:\n",
    "#             if col in patient_x_task_y_data.columns and not patient_x_task_y_data[col].isnull().values.any():\n",
    "#                 patient_x_task_y_data.fillna(means_col_val[col], inplace=True)\n",
    "        if 'label' not in patient_x_task_y_data.columns:\n",
    "            continue\n",
    "        if patient_x_task_y_data.isnull().values.any():\n",
    "            print(\"============= Detected Null ===================\")\n",
    "        \n",
    "        # Remove unusable columns\n",
    "        patient_x_task_y_data = patient_x_task_y_data[usable]\n",
    "        \n",
    "        # Break into windows\n",
    "        i = 0\n",
    "        while i < len(patient_x_task_y_data) - window_size - 1:\n",
    "            window = patient_x_task_y_data.loc[i: i + window_size - 1].values\n",
    "            window = np.expand_dims(window, axis=0)\n",
    "            \n",
    "            \n",
    "            if patient_data is None:\n",
    "                patient_data = window\n",
    "            else:\n",
    "                patient_data = np.concatenate([patient_data, window], axis=0)\n",
    "            i += jump\n",
    "    np.save(f'{patient_id}.npy', patient_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "init_split = sample([pid for pid in all_patient_ids if '008' not in pid], 4)\n",
    "train_ids = [i for i in all_patient_ids if i not in init_split]\n",
    "val_ids = sample(init_split,  2)\n",
    "test_ids = [i for i in init_split if i not in val_ids]\n",
    "\n",
    "data_group = {'train':None, 'val':None, 'test':None}\n",
    "for patient_id in all_patient_ids:\n",
    "    patient_data = np.load(f'{patient_id}.npy', allow_pickle=True)\n",
    "    \n",
    "    group_type = 'train'\n",
    "    if patient_id in val_ids: group_type='val'\n",
    "    elif patient_id in test_ids: group_type='test'\n",
    "    \n",
    "    if data_group[group_type] is None:\n",
    "        data_group[group_type] = patient_data\n",
    "    else:\n",
    "        if len(patient_data.shape) == 3:\n",
    "            data_group[group_type] = np.concatenate([data_group[group_type], patient_data], axis=0)\n",
    "            \n",
    "    os.remove(f'{patient_id}.npy')\n",
    "        \n",
    "np.save('train_group.npy', data_group)\n",
    "\n",
    "\n",
    "for t, data in data_group.items():\n",
    "    x = data[:, :, 0:-1]\n",
    "    y = data[:, :, -1]\n",
    "    prefix = \"zero-imp_1000_dataset_ps\"\n",
    "    np.save(f'{prefix}/x_{t}.npy', x)\n",
    "    np.save(f'{prefix}/y_{t}.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ids, val_ids, test_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
